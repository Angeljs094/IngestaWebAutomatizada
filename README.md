# Ingesta Web Automatizada 锔

Proyecto final orientado a la **automatizaci贸n de ingesta y procesamiento de datos web** hacia una base de datos relacional.  
El flujo implementa t茅cnicas de **web scraping, limpieza de datos, reglas de negocio y carga estructurada con SQLAlchemy**, garantizando un proceso **escalable y profesional**.

---

##  Objetivo

Desarrollar un flujo completo que:
- Extraiga informaci贸n desde una fuente web p煤blica.
- Procese y limpie los datos aplicando reglas de negocio.
- Cargue los resultados en una base de datos relacional mediante **SQLAlchemy ORM**.

---

##  Contexto del Proyecto

La empresa requiere obtener informaci贸n estructurada de libros del g茅nero **Fantasy** disponibles en el portal [Books to Scrape](https://books.toscrape.com).  
El objetivo es extraer esta informaci贸n, procesarla seg煤n reglas definidas y almacenarla en una base de datos corporativa.

---

##  Requerimiento Principal

Extraer todos los libros del g茅nero **Fantasy** y cargarlos en la base de datos cumpliendo las siguientes reglas:

- **Tabla final:** `books_for_sale`
- **Campos requeridos:**
  - `book_code`: C贸digo 煤nico e incremental.
  - `book_name`: Nombre del libro (sin el contenido entre par茅ntesis).
  - `book_detail`: Texto extra铆do de los par茅ntesis del nombre (si aplica).
  - `book_price`: Precio del libro (tipo num茅rico).

---

##  Flujo del Proceso

1. Navegar a la categor铆a *Fantasy*.  
2. Capturar al menos 3 atributos de cada libro.  
3. Extraer informaci贸n de todos los libros de la primera p谩gina.  
4. Extender la extracci贸n a todas las p谩ginas de la categor铆a.  
5. Crear la tabla `books_for_sale` con SQLAlchemy ORM.  
6. Aplicar reglas de negocio al cargar los datos.  
7. Implementar concurrencia en la carga hacia la base de datos.  

**Evaluaciones adicionales:**
- No incluir librer铆as innecesarias.  
- Cerrar el navegador correctamente al terminar el scrapeo.  

**Bonos:**
- Desarrollo modular (todo en funciones).  
- Uso de `WebDriverWait` para sincronizaci贸n eficiente.  

---

##  Estructura del Proyecto

- DATABASE/        # Contiene la base de datos SQLite (books.db)
- DOCS/            # Documentaci贸n del proyecto (adp_proyecto.pdf)
- NOTEBOOKS/       # Jupyter Notebooks para an谩lisis y desarrollo

---

##  Tecnolog铆as utilizadas

- **Python 3.x**
- **Jupyter Notebook**
- **SQLite + SQLAlchemy ORM**
- Librer铆as de scraping: `requests`, `BeautifulSoup4`, `selenium`
- Librer铆as de an谩lisis: `pandas`, `numpy`

---

## 锔 Instalaci贸n y uso

1. Clona el repositorio:
   ```bash
   git clone https://github.com/Angeljs094/IngestaWebAutomatizada.git
   cd IngestaWebAutomatizada

